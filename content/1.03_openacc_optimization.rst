.. _openacc-optimization:

OpenACC: Optimization
=====================

- Data movement is and important part to optimize when using GPUs
    - Keeping data on the GPU as long as possible
- Getting the compiler to generate parallel code
    - Addressing loop dependencies
- Data access and execution divergence are important for GPU performance


Optimizing data movement
^^^^^^^^^^^^^^^^^^^^^^^^

-  Minimize the data transfer between host and device

-  Constructs and clauses for

   -  defining the variables on the device
   -  transferring data to/from the device

-  All variables used inside the ``parallel`` or ``kernels`` region will
   be treated as *implicit* variables if they are not present in any
   data clauses, i.e. copying to and from to the device is automatically
   performed

(refer to *examples/OpenACC/himeno/solution/C/himeno_C_v01.c*)

 .. code:: c

 #pragma acc parallel loop private(i,j,k,s0,ss) reduction(+:gosa)
 for(i=1 ; i<imax-1 ; ++i)

 .. code:: c
 $ export PGI_ACC_TIME=1
 $ ./himeno.x
  jacobi  NVIDIA  devicenum=0
    time(us): 24,912,728
    215: compute region reached 4 times
        215: kernel launched 4 times
            grid: [510]  block: [128]
             device time(us): total=6,735 max=1,693 min=1,678 avg=1,683
            elapsed time(us): total=6,998 max=1,763 min=1,741 avg=1,749
        215: reduction kernel launched 4 times
            grid: [1]  block: [256]
             device time(us): total=17 max=5 min=4 avg=4
            elapsed time(us): total=104 max=28 min=25 avg=26
    215: data region reached 8 times
        215: data copyin transfers: 3115092
             device time(us): total=18,715,892 max=787 min=4 avg=6
        237: data copyout transfers: 518164
             device time(us): total=6,190,084 max=230 min=11 avg=11
 
(refer to *examples/OpenACC/himeno/solution/C/himeno_C_v02.c*)
 .. code:: c
 #pragma acc data copyin(a,b,c,bnd,wrk1) copy(p) create(wrk2)
  {
  for(n=0;n<nn;++n){
    gosa = 0.0;

 #pragma acc parallel loop private(i,j,k,s0,ss) reduction(+:gosa)
    for(i=1 ; i<imax-1 ; ++i)
      for(j=1 ; j<jmax-1 ; ++j)
        for(k=1 ; k<kmax-1 ; ++k){

 .. code:: c
 $ export PGI_ACC_TIME=1
 $ ./himeno.x
  jacobi  NVIDIA  devicenum=0
    time(us): 389,951
    212: data region reached 4 times
        212: data copyin transfers: 220
             device time(us): total=148,455 max=4,814 min=60 avg=674
        247: data copyout transfers: 18
             device time(us): total=30,017 max=2,130 min=163 avg=1,667
    217: compute region reached 101 times
        217: kernel launched 101 times
            grid: [510]  block: [128]
             device time(us): total=168,823 max=1,734 min=1,656 avg=1,671
            elapsed time(us): total=171,048 max=1,761 min=1,676 avg=1,693
        217: reduction kernel launched 101 times
            grid: [1]  block: [256]
             device time(us): total=560 max=7 min=5 avg=5
            elapsed time(us): total=2,861 max=209 min=24 avg=28
    217: data region reached 202 times
        217: data copyin transfers: 101
             device time(us): total=589 max=14 min=5 avg=5
        239: data copyout transfers: 101
             device time(us): total=1,520 max=24 min=13 avg=15
    242: compute region reached 101 times
        242: kernel launched 101 times
            grid: [510]  block: [128]
             device time(us): total=39,987 max=435 min=389 avg=395
            elapsed time(us): total=42,470 max=467 min=412 avg=420


Optimize Loop performance
-------------------------

- The compiler is usually pretty good at choosing how to break up loop iterations to run well on parallel accelerators.

- Sometimes we can obtain a little more performance by guiding the compiler to make specific choices.

Collapse Clause
^^^^^^^^^^^^^^^

- collapse(N)

  - Same as in OpenMP, take the next N tightly nested loops and flatten them into a one loop
  - Can be beneficial when loops are small
  - Breaks the next loops into tiles (blocks) before parallelizing the loops
  - For certain memory access patterns this can improve data locality

# - The collapse clause allows us to transform a multi-dimensional loop nest into a single-dimensional loop. This process is helpful for increasing the overall length (which usually increases parallelism) of our loops, and will often help with memory locality.

(refer to *examples/OpenACC/himeno/solution/C/himeno_C_v03.c*)

 .. code:: c
 #pragma acc parallel loop collapse(3) private(i,j,k,s0,ss) reduction(+:gosa)
    for(i=1 ; i<imax-1 ; ++i)
      for(j=1 ; j<jmax-1 ; ++j)
        for(k=1 ; k<kmax-1 ; ++k){

 .. code:: c
 $ export PGI_ACC_TIME=1
 $ ./himeno.x
  jacobi  NVIDIA  devicenum=0
    time(us): 4,062,105
    221: data region reached 4 times
    226: compute region reached 2214 times
        226: kernel launched 2214 times
            grid: [65535]  block: [128]
             device time(us): total=3,252,373 max=1,560 min=1,465 avg=1,469
            elapsed time(us): total=3,296,349 max=1,664 min=1,484 avg=1,488
        226: reduction kernel launched 2214 times
            grid: [1]  block: [256]
             device time(us): total=260,194 max=261 min=114 avg=117
            elapsed time(us): total=304,827 max=344 min=133 avg=137
 

Loop directive
--------------

- Loop directive accepts several fine-tuning clauses

 - gang -- apply gang-level parallelism
 - worker -- apply worker-level parallelism
 - vector -- apply vector-level parallelism
 - seq -- run sequentially

- Multiple levels can be applied to a loop nest, but they have to be applied in top-down order

What values should I try?
-------------------------

- Depends on the accelerator you are using
- You can try out different combinations, but deterministic optimizations require good knowledge on the accelerator hardware

  - In the case of NVIDIA GPUs you should start with the NVVP results and refer to CUDA documentation
  - One hard-coded value: for NVIDIA GPUs the vector length should always be 32, which is the (current) warp size


Optimize loops: vector length
-----------------------------

- Tell the compiler that when using NVIDIA device it should use a vector length of 32 on the innermost loop
- Because these parameters depend on the accelerator type, it is a good practice to add device_type clause

.. code:: c   

   for (int i=0; i<imax; i++) {
       ...
       #pragma acc loop device_type(nvidia) vector(32)
       for (int j=0; j<jmax; j++) {
           ... /* No further loops in this block */
       }
    }

Optimize loops: specifying workers
----------------------------------

.. code:: c

   #pragma acc loop device_type(nvidia) gang worker(32)
   for (int i=0; i<imax; i++) {
       ...
       #pragma acc loop device_type(nvidia) vector(32)
       for (int j=0; j<jmax; j++) {
           ...
       }
    }

 - Tell the compiler that when using NVIDIA device, the outer loop should be broken over gangs and workers with 32 workers per gang


Additional loop optimizations
-----------------------------

Branches in device code
-----------------------

- 32 threads running the same instruction at the same time
- Avoid branches based on thread id unless evenly dividable by 32

  - If (i%2) NO!
  - if (i%32) ok

- When unavoidable keep branches short


Summary
-------

- Profiling is essential for optimization

  - NVPROF and NVVP for NVIDIA platform

- Data and Loop optimizations
