.. _openacc-optimization:

OpenACC: Optimization
=====================

- Data movement is and important part to optimize when using GPUs
    - Keeping data on the GPU as long as possible
- Getting the compiler to generate parallel code
    - Addressing loop dependencies
- Data access and execution divergence are important for GPU performance


Loop dependencies
^^^^^^^^^^^^^^^^^^

.. code:: c

 /* FLOW dependency, k>0 */
 for (int i=0; i<N; i++)
    A[i] = A[i-k]+1;
 /* ANTI dependency, k>0 */
 for (int i=0; i<N; i++)
    A[i] = A[i+k]+1;
 ! FLOW dependency, k>0
 do i=0, N
    a(i) = a(i-k) + 1;
 end do
 ! ANTI dependency, k>0
 do i=0, N
    a(i) = a(i+k) + 1;
 end do

Loop dependencies
-----------------

- Dependencies disable vectorization, which is essential for good performance 
- Rewrite the loops so that the dependency is removed
- Try to split the loop, use temporary array, etc.
- Some dependencies can not be removed
  - Try a different algorithm?


Loop dependencies and C
-----------------------

- C pointers are hard for the compiler to follow
  - Compiler will not know, if a loop can be vectorized safely, if a function has pointer arguments
  - Can be a false dependency

.. code:: c

   void adder(float *x, float *y, float *res) {
      for (int i=0; i < VECSIZE; i++) {
          res[i] = x[i] + y[i];
      }
   }

- What if res and x overlap in memory?

C99 restrict keyword
^^^^^^^^^^^^^^^^^^^^

C99 standard has restrict keyword which tells the compiler that the pointer is accessed so that it does not overlap with other accesses

.. code:: c

   void adder(float restrict *x, float restrict *y, float restrict *res) {
       for (int i=0; i < VECSIZE; i++) {
           res[i] = x[i] + y[i];
       }
   }

Loop independent clause
-----------------------

- OpenACC independent clause tells to the compiler that loop iterations are independent
 - Overrides any compiler dependency analysis
 - You have to make sure that the iterations are independent!

.. code:: c

   #pragma acc loop independent
   void adder(float *x, float *y, float *res) {
       for (int i=0; i < VECSIZE; i++) {
           res[i] = x[i] + y[i];
       }
    }

Loop directive
--------------

- Loop directive accepts several fine-tuning clauses

 - gang -- apply gang-level parallelism
 - worker -- apply worker-level parallelism
 - vector -- apply vector-level parallelism
 - seq -- run sequentially

- Multiple levels can be applied to a loop nest, but they have to be applied in top-down order

Optimize loops: vector length
-----------------------------

- Tell the compiler that when using NVIDIA device it should use a vector length of 32 on the innermost loop
- Because these parameters depend on the accelerator type, it is a good practice to add device_type clause

.. code:: c   

   for (int i=0; i<imax; i++) {
       ...
       #pragma acc loop device_type(nvidia) vector(32)
       for (int j=0; j<jmax; j++) {
           ... /* No further loops in this block */
       }
    }

Optimize loops: specifying workers
----------------------------------

.. code:: c

   #pragma acc loop device_type(nvidia) gang worker(32)
   for (int i=0; i<imax; i++) {
       ...
       #pragma acc loop device_type(nvidia) vector(32)
       for (int j=0; j<jmax; j++) {
           ...
       }
    }

 - Tell the compiler that when using NVIDIA device, the outer loop should be broken over gangs and workers with 32 workers per gang


Additional loop optimizations
-----------------------------

- collapse(N)

  - Same as in OpenMP, take the next N tightly nested loops and flatten them into a one loop
  - Can be beneficial when loops are small
  - Breaks the next loops into tiles (blocks) before parallelizing the loops
  - For certain memory access patterns this can improve data locality

What values should I try?
-------------------------

- Depends on the accelerator you are using
- You can try out different combinations, but deterministic optimizations require good knowledge on the accelerator hardware

  - In the case of NVIDIA GPUs you should start with the NVVP results and refer to CUDA documentation
  - One hard-coded value: for NVIDIA GPUs the vector length should always be 32, which is the (current) warp size


Branches in device code
-----------------------

- 32 threads running the same instruction at the same time
- Avoid branches based on thread id unless evenly dividable by 32

  - If (i%2) NO!
  - if (i%32) ok

- When unavoidable keep branches short

Coalesced memory access
-----------------------

- Coalesced memory access

  - 32 threads accessing memory at the same time
  - 32 Byte access granularity
  - Overly simplified
  - Some cases 128 bytes access granularity
  - 128 byte coalesced accesses can improve performance

  ![](img/memory-access.png)

Summary
-------

- Profiling is essential for optimization

  - NVPROF and NVVP for NVIDIA platform

- Loop optimizations
- Branches
- Memory access patterns

